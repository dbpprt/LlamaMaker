{
    "configurations": [
        // {
        //     "name": "(fp16/bf16) train.py",
        //     "type": "python",
        //     "request": "launch",
        //     "cwd": "${workspaceFolder}",
        //     "module": "accelerate.commands.launch",
        //     "args": [
        //         "--config_file=./config/local.yaml",
        //         "train.py",
        //         "--use_4bit_training",
        //         "--model_id",
        //         "google/gemma-2b",
        //         "--per_device_train_batch_size",
        //         "4",
        //         "--gradient_accumulation_steps",
        //         "4"
        //     ],
        //     "console": "integratedTerminal"
        // },
        // {
        //     "name": "(unslooth,2B) train.py",
        //     "type": "python",
        //     "request": "launch",
        //     "cwd": "${workspaceFolder}",
        //     "module": "accelerate.commands.launch",
        //     "args": [
        //         "--config_file=./config/local.yaml",
        //         "train.py",
        //         "--use_unslooth",
        //         "--model_id",
        //         "unsloth/gemma-2b-bnb-4bit",
        //         "--per_device_train_batch_size",
        //         "16",
        //         "--gradient_accumulation_steps",
        //         "4",
        //         "--learning_rate",
        //         "0.0001",
        //         "--num_train_epochs",
        //         "3"

        //     ],
        //     "console": "integratedTerminal"
        // },
        // {
        //     "name": "(unslooth,2B,it,full prompt) train.py",
        //     "type": "python",
        //     "request": "launch",
        //     "cwd": "${workspaceFolder}",
        //     "module": "accelerate.commands.launch",
        //     "args": [
        //         "--config_file=./config/local.yaml",
        //         "train.py",
        //         "--use_unslooth",
        //         "--model_id",
        //         "unsloth/gemma-2b-it-bnb-4bit",
        //         "--data_config",
        //         "./data/product_clustering/pretrain_full_prompt.yaml",
        //         "--max_seq_length",
        //         "1024",
        //         "--per_device_train_batch_size",
        //         "8",
        //         "--gradient_accumulation_steps",
        //         "8",
        //         "--learning_rate",
        //         "0.0001",
        //         "--num_train_epochs",
        //         "3"

        //     ],
        //     "console": "integratedTerminal"
        // },
        // {
        //     "name": "(unslooth,7B) train.py",
        //     "type": "python",
        //     "request": "launch",
        //     "cwd": "${workspaceFolder}",
        //     "module": "accelerate.commands.launch",
        //     "args": [
        //         "--config_file=./config/local.yaml",
        //         "train.py",
        //         "--use_unslooth",
        //         "--model_id",
        //         "unsloth/gemma-7b-bnb-4bit",
        //         "--per_device_train_batch_size",
        //         "8",
        //         "--gradient_accumulation_steps",
        //         "1"
        //     ],
        //     "console": "integratedTerminal"
        // },
        // {
        //     "name": "(unslooth,7B, mistral) train.py",
        //     "type": "python",
        //     "request": "launch",
        //     "cwd": "${workspaceFolder}",
        //     "module": "accelerate.commands.launch",
        //     "args": [
        //         "--config_file=./config/local.yaml",
        //         "train.py",
        //         "--use_unslooth",
        //         "--model_id",
        //         "NousResearch/Hermes-2-Pro-Mistral-7B",
        //         "--data_config",
        //         "./data/product_clustering/pretrain_no_prompt_mistral.yaml",
        //         "--per_device_train_batch_size",
        //         "32",
        //         "--per_device_eval_batch_size",
        //         "32",
        //         "--gradient_accumulation_steps",
        //         "1"
        //     ],
        //     "console": "integratedTerminal"
        // },
        // {
        //     "name": "(unslooth,7B, mistral, full prompt) train.py",
        //     "type": "python",
        //     "request": "launch",
        //     "cwd": "${workspaceFolder}",
        //     "module": "accelerate.commands.launch",
        //     "args": [
        //         "--config_file=./config/local.yaml",
        //         "train.py",
        //         "--use_unslooth",
        //         "--model_id",
        //         "NousResearch/Hermes-2-Pro-Mistral-7B",
        //         "--data_config",
        //         "./data/product_clustering/pretrain_full_prompt_mistral.yaml",
        //         "--per_device_train_batch_size",
        //         "8",
        //         "--gradient_accumulation_steps",
        //         "1",
        //         "--max_seq_length",
        //         "1024",
        //     ],
        //     "console": "integratedTerminal"
        // },
        // {
        //     "name": "(unslooth,mistral7b,shopgpt) train.py",
        //     "type": "python",
        //     "request": "launch",
        //     "cwd": "${workspaceFolder}",
        //     "module": "accelerate.commands.launch",
        //     "args": [
        //         "--config_file=./config/local.yaml",
        //         "train.py",
        //         "--use_unslooth",
        //         "--model_id",
        //         "NousResearch/Hermes-2-Pro-Mistral-7B",
        //         "--data_config",
        //         "./data/shopgpt/no_prompt_mistral.yaml",
        //         "--per_device_train_batch_size",
        //         "8",
        //         "--per_device_eval_batch_size",
        //         "8",
        //         "--gradient_accumulation_steps",
        //         "1",
        //         "--max_seq_length",
        //         "3072",
        //         "--logging_steps",
        //         "1",
        //         "--num_train_epochs",
        //         "1",
        //         // The values used in the QLoRA paper were r=64 and lora_alpha=16, and these are said to generalize well
        //         "--lora_r",
        //         "32",
        //         "--lora_alpha",
        //         "64"
        //     ],
        //     "console": "integratedTerminal"
        // },
        // {
        //     "name": "(mistral7b,shopgpt) train.py",
        //     "type": "python",
        //     "request": "launch",
        //     "cwd": "${workspaceFolder}",
        //     "module": "accelerate.commands.launch",
        //     "args": [
        //         "--config_file=./config/local.yaml",
        //         "train.py",
        //         // "--use_unslooth",
        //         "--model_id",
        //         "NousResearch/Hermes-2-Pro-Mistral-7B",
        //         "--data_config",
        //         "./data/shopgpt/no_prompt_mistral.yaml",
        //         "--per_device_train_batch_size",
        //         "1",
        //         "--per_device_eval_batch_size",
        //         "1",
        //         "--gradient_accumulation_steps",
        //         "8",
        //         "--max_seq_length",
        //         "3072",
        //         "--logging_steps",
        //         "1",
        //         "--num_train_epochs",
        //         "1",
        //         // The values used in the QLoRA paper were r=64 and lora_alpha=16, and these are said to generalize well
        //         "--lora_r",
        //         "64",
        //         "--lora_alpha",
        //         "16"
        //     ],
        //     "console": "integratedTerminal"
        // },
        // {
        //     "name": "(llama3-8b,shopgpt) train.py",
        //     "type": "python",
        //     "request": "launch",
        //     "cwd": "${workspaceFolder}",
        //     "module": "accelerate.commands.launch",
        //     "args": [
        //         "--config_file=./config/local.yaml",
        //         "train.py",
        //         // "--use_unslooth",
        //         "--model_id",
        //         // this one is not gated
        //         "NousResearch/Meta-Llama-3-8B-Instruct",
        //         "--data_config",
        //         "./data/shopgpt/no_prompt_llama3.yaml",
        //         "--per_device_train_batch_size",
        //         "1",
        //         "--per_device_eval_batch_size",
        //         "1",
        //         "--gradient_accumulation_steps",
        //         "8",
        //         "--max_seq_length",
        //         "3072",
        //         "--logging_steps",
        //         "1",
        //         "--num_train_epochs",
        //         "10",
        //         // The values used in the QLoRA paper were r=64 and lora_alpha=16, and these are said to generalize well
        //         "--lora_r",
        //         "64",
        //         "--lora_alpha",
        //         "16"
        //     ],
        //     "console": "integratedTerminal"
        // },
        // {
        //     "name": "(llama3-8b,mintaka) train.py",
        //     "type": "python",
        //     "request": "launch",
        //     "cwd": "${workspaceFolder}",
        //     "module": "accelerate.commands.launch",
        //     "args": [
        //         "--config_file=./config/local.yaml",
        //         "train.py",
        //         // "--use_unslooth",
        //         "--model_id",
        //         // this one is not gated
        //         "NousResearch/Meta-Llama-3-8B-Instruct",
        //         "--data_config",
        //         "./data/mintaka/llama3.yaml",
        //         "--per_device_train_batch_size",
        //         "16",
        //         "--per_device_eval_batch_size",
        //         "24",
        //         "--gradient_accumulation_steps",
        //         "2",
        //         "--max_seq_length",
        //         "256",
        //         "--logging_steps",
        //         "1",
        //         "--eval_steps",
        //         "100",
        //         "--save_steps",
        //         "100",
        //         "--num_train_epochs",
        //         "3",
        //         // The values used in the QLoRA paper were r=64 and lora_alpha=16, and these are said to generalize well
        //         "--lora_r",
        //         "128",
        //         "--lora_alpha",
        //         "256",
        //         "--lora_dropout",
        //         "0.1"
        //     ],
        //     "console": "integratedTerminal"
        // },
        // {
        //     "name": "(tinyllama,mintaka) train.py",
        //     "type": "python",
        //     "request": "launch",
        //     "cwd": "${workspaceFolder}",
        //     "module": "accelerate.commands.launch",
        //     "args": [
        //         "--config_file=./config/local.yaml",
        //         "train.py",
        //         // "--use_unslooth",
        //         "--model_id",
        //         // this one is not gated
        //         "TinyLlama/TinyLlama-1.1B-Chat-v0.4",
        //         "--data_config",
        //         "./data/mintaka/tinyllama.yaml",
        //         "--per_device_train_batch_size",
        //         "16",
        //         "--per_device_eval_batch_size",
        //         "24",
        //         "--gradient_accumulation_steps",
        //         "8",
        //         "--max_seq_length",
        //         "256",
        //         "--logging_steps",
        //         "1",
        //         "--eval_steps",
        //         "50",
        //         "--save_steps",
        //         "50",
        //         "--num_train_epochs",
        //         "3",
        //         // The values used in the QLoRA paper were r=64 and lora_alpha=16, and these are said to generalize well
        //         "--lora_r",
        //         "512",
        //         "--lora_alpha",
        //         "1024",
        //         "--lora_dropout",
        //         "0.1"
        //     ],
        //     "console": "integratedTerminal"
        // },
        {
            "name": "(debug,apple-silicon)(tinyllama,swisstext) train.py",
            "type": "python",
            "request": "launch",
            "cwd": "${workspaceFolder}",
            "module": "accelerate.commands.launch",
            "args": [
                "--config_file=./config/local.yaml",
                "train.py",
                // "--use_unslooth",
                "--model_id",
                // this one is not gated
                "TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T",
                "--data_config",
                "./data/swisstext2023/llama3.yaml",
                // use debug mode locally
                "--debug",
                "--per_device_train_batch_size",
                "1",
                "--per_device_eval_batch_size",
                "1",
                "--gradient_accumulation_steps",
                "1",
                "--max_seq_length",
                "256",
                "--logging_steps",
                "1",
                "--eval_steps",
                "1",
                "--save_steps",
                "50",
                "--num_train_epochs",
                "1",
                "--optim",
                "adamw_hf",
                "--lora_modules_to_save",
                "embed_tokens",
                // The values used in the QLoRA paper were r=64 and lora_alpha=16, and these are said to generalize well
                "--lora_r",
                "64",
                "--lora_alpha",
                "16",
                "--lora_dropout",
                "0.1"
            ],
            "console": "integratedTerminal"
        },
        {
            "name": "(llama3-8b,swisstext) train.py",
            "type": "python",
            "request": "launch",
            "cwd": "${workspaceFolder}",
            "module": "accelerate.commands.launch",
            "args": [
                "--config_file=./config/local.yaml",
                "train.py",
                // "--use_unslooth",
                "--model_id",
                // this one is not gated
                "NousResearch/Meta-Llama-3-8B",
                "--data_config",
                "./data/swisstext2023/llama3.yaml",
                "--per_device_train_batch_size",
                "1",
                "--per_device_eval_batch_size",
                "2",
                "--gradient_accumulation_steps",
                "32",
                "--max_seq_length",
                "2048",
                "--logging_steps",
                "1",
                "--eval_steps",
                "100",
                "--save_steps",
                "100",
                "--num_train_epochs",
                "3",
                // The values used in the QLoRA paper were r=64 and lora_alpha=16, and these are said to generalize well
                "--lora_r",
                "64",
                "--lora_alpha",
                "16",
                "--lora_dropout",
                "0.1"
            ],
            "console": "integratedTerminal"
        },{
            "name": "SM(llama3-8b,swisstext) train.py",
            "type": "python",
            "request": "launch",
            "cwd": "${workspaceFolder}",
            "module": "accelerate.commands.launch",
            "args": [
                "--config_file=./config/sagemaker.yaml",
                "train.py",
                // "--use_unslooth",
                "--model_id",
                // this one is not gated
                "NousResearch/Meta-Llama-3-8B",
                "--data_config",
                "./data/swisstext2023/llama3.yaml",
                "--per_device_train_batch_size",
                "32",
                "--per_device_eval_batch_size",
                "64",
                "--gradient_accumulation_steps",
                "4",
                "--max_seq_length",
                "2048",
                "--logging_steps",
                "1",
                "--eval_steps",
                "100",
                "--save_steps",
                "100",
                "--num_train_epochs",
                "3",
                // The values used in the QLoRA paper were r=64 and lora_alpha=16, and these are said to generalize well
                "--lora_r",
                "64",
                "--lora_alpha",
                "16",
                "--lora_dropout",
                "0.1",
                // all-linear is not supported in the current peft version on sagemaker
                "--lora_target_modules",
                "q_proj,k_proj,v_proj,o_proj,gate_proj,down_proj,up_proj,lm_head",
                // uncomment to fine-tune embeddings
                // "--lora_modules_to_save",
                // "embed_tokens",
            ],
            "console": "integratedTerminal"
        }
    ]
}